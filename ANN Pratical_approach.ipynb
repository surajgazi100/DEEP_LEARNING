{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled44.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMUZaogGY3HGX2VEJIu/1I1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surajgazi100/DEEP_LEARNING/blob/main/ANN%20Pratical_approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjBBP5-5aMfC"
      },
      "source": [
        "ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQi8SbdNgBG0"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5oFB5LqgO-F",
        "outputId": "a0c16988-0f09-48f1-847f-994fcba3a1e0",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e50b8cbc-63c2-423b-83bf-cb4d3b2c5d8f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e50b8cbc-63c2-423b-83bf-cb4d3b2c5d8f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Churn_Modelling.csv to Churn_Modelling.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2q_ltKugaub"
      },
      "source": [
        "df = pd.read_csv('Churn_Modelling.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgR_g3Lugl6P",
        "outputId": "25c31a5b-1c20-421f-fc49-0955ac04d433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "3          4    15701354      Boni  ...               0        93826.63      0\n",
              "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpgv-e5uhJAn"
      },
      "source": [
        "property DataFrame.iloc\n",
        "Purely integer-location based indexing for selection by position.\n",
        "\n",
        ".iloc[] is primarily integer position based (from 0 to length-1 of the axis), but may also be used with a boolean array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4rv0ZhSgrz1"
      },
      "source": [
        "x =  df.iloc[:,3:13]\n",
        "y = df.iloc[:,13]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIDwvYgRhRXV",
        "outputId": "38762d82-f704-4989-85b3-cba488a9b9a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>771</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>516</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>709</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>772</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Male</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>792</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      CreditScore Geography  Gender  ...  HasCrCard  IsActiveMember  EstimatedSalary\n",
              "0             619    France  Female  ...          1               1        101348.88\n",
              "1             608     Spain  Female  ...          0               1        112542.58\n",
              "2             502    France  Female  ...          1               0        113931.57\n",
              "3             699    France  Female  ...          0               0         93826.63\n",
              "4             850     Spain  Female  ...          1               1         79084.10\n",
              "...           ...       ...     ...  ...        ...             ...              ...\n",
              "9995          771    France    Male  ...          1               0         96270.64\n",
              "9996          516    France    Male  ...          1               1        101699.77\n",
              "9997          709    France  Female  ...          0               1         42085.58\n",
              "9998          772   Germany    Male  ...          1               0         92888.52\n",
              "9999          792    France  Female  ...          1               0         38190.78\n",
              "\n",
              "[10000 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvLrv1AMhd9r",
        "outputId": "928443a7-56c0-4012-e768-e9972cc6ccff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1       0\n",
              "2       1\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "9995    0\n",
              "9996    0\n",
              "9997    1\n",
              "9998    1\n",
              "9999    0\n",
              "Name: Exited, Length: 10000, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RMywPy5hg0R"
      },
      "source": [
        "#create dummy Variables\n",
        "geography = pd.get_dummies(x['Geography'],drop_first=True)\n",
        "gender=pd.get_dummies(x['Gender'],drop_first=True)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emO7C0G6iLjE"
      },
      "source": [
        "#concatenate the Data frames\n",
        "x = pd.concat([x,geography,gender],axis=1)\n",
        "#Drop unnecessary columns \n",
        "x = x.drop(['Geography','Gender'],axis=1)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3o_XOfui43A",
        "outputId": "635e11d4-e369-4e8b-d74c-4874d4e21ef0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Germany</th>\n",
              "      <th>Spain</th>\n",
              "      <th>Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>771</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>516</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>709</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>772</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>792</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      CreditScore  Age  Tenure  ...  Germany  Spain  Male\n",
              "0             619   42       2  ...        0      0     0\n",
              "1             608   41       1  ...        0      1     0\n",
              "2             502   42       8  ...        0      0     0\n",
              "3             699   39       1  ...        0      0     0\n",
              "4             850   43       2  ...        0      1     0\n",
              "...           ...  ...     ...  ...      ...    ...   ...\n",
              "9995          771   39       5  ...        0      0     1\n",
              "9996          516   35      10  ...        0      0     1\n",
              "9997          709   36       7  ...        0      0     0\n",
              "9998          772   42       3  ...        1      0     1\n",
              "9999          792   28       4  ...        0      0     0\n",
              "\n",
              "[10000 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCCSuMvLi8FH"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hz87OsbjaUC",
        "outputId": "71f6db44-e33f-4ed6-adf2-9185b90369e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "x_test"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Germany</th>\n",
              "      <th>Spain</th>\n",
              "      <th>Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9394</th>\n",
              "      <td>597</td>\n",
              "      <td>35</td>\n",
              "      <td>8</td>\n",
              "      <td>131101.04</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>192852.67</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>898</th>\n",
              "      <td>523</td>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "      <td>102967.41</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>128702.10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2398</th>\n",
              "      <td>706</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>95386.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>75732.25</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5906</th>\n",
              "      <td>788</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>112079.58</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>89368.59</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2343</th>\n",
              "      <td>706</td>\n",
              "      <td>38</td>\n",
              "      <td>5</td>\n",
              "      <td>163034.82</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>135662.17</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1037</th>\n",
              "      <td>625</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>180969.55</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2899</th>\n",
              "      <td>586</td>\n",
              "      <td>35</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>70760.69</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9549</th>\n",
              "      <td>578</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>157267.95</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>141533.19</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2740</th>\n",
              "      <td>650</td>\n",
              "      <td>34</td>\n",
              "      <td>4</td>\n",
              "      <td>142393.11</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11276.48</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6690</th>\n",
              "      <td>573</td>\n",
              "      <td>30</td>\n",
              "      <td>8</td>\n",
              "      <td>127406.50</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>192950.60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      CreditScore  Age  Tenure  ...  Germany  Spain  Male\n",
              "9394          597   35       8  ...        1      0     0\n",
              "898           523   40       2  ...        0      0     0\n",
              "2398          706   42       8  ...        0      1     0\n",
              "5906          788   32       4  ...        0      0     1\n",
              "2343          706   38       5  ...        1      0     1\n",
              "...           ...  ...     ...  ...      ...    ...   ...\n",
              "1037          625   24       1  ...        0      0     0\n",
              "2899          586   35       7  ...        0      0     0\n",
              "9549          578   36       1  ...        0      1     1\n",
              "2740          650   34       4  ...        1      0     1\n",
              "6690          573   30       8  ...        1      0     1\n",
              "\n",
              "[2000 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqKNH4u2jfgv",
        "outputId": "60502341-eeea-45f0-f9fe-5de285227418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "x_train"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Germany</th>\n",
              "      <th>Spain</th>\n",
              "      <th>Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7389</th>\n",
              "      <td>667</td>\n",
              "      <td>34</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>163830.64</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9275</th>\n",
              "      <td>427</td>\n",
              "      <td>42</td>\n",
              "      <td>1</td>\n",
              "      <td>75681.52</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>57098.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>535</td>\n",
              "      <td>29</td>\n",
              "      <td>2</td>\n",
              "      <td>112367.34</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>185630.76</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5316</th>\n",
              "      <td>654</td>\n",
              "      <td>40</td>\n",
              "      <td>5</td>\n",
              "      <td>105683.63</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>173617.09</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>850</td>\n",
              "      <td>57</td>\n",
              "      <td>8</td>\n",
              "      <td>126776.30</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>132298.49</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9225</th>\n",
              "      <td>594</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>120074.97</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>162961.79</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4859</th>\n",
              "      <td>794</td>\n",
              "      <td>22</td>\n",
              "      <td>4</td>\n",
              "      <td>114440.24</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>107753.07</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3264</th>\n",
              "      <td>738</td>\n",
              "      <td>35</td>\n",
              "      <td>5</td>\n",
              "      <td>161274.05</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>181429.87</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9845</th>\n",
              "      <td>590</td>\n",
              "      <td>38</td>\n",
              "      <td>9</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>148750.16</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2732</th>\n",
              "      <td>623</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>108076.33</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>118855.26</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      CreditScore  Age  Tenure  ...  Germany  Spain  Male\n",
              "7389          667   34       5  ...        0      1     0\n",
              "9275          427   42       1  ...        1      0     1\n",
              "2995          535   29       2  ...        0      0     0\n",
              "5316          654   40       5  ...        0      1     1\n",
              "356           850   57       8  ...        0      1     0\n",
              "...           ...  ...     ...  ...      ...    ...   ...\n",
              "9225          594   32       4  ...        1      0     0\n",
              "4859          794   22       4  ...        0      1     0\n",
              "3264          738   35       5  ...        0      0     1\n",
              "9845          590   38       9  ...        0      1     0\n",
              "2732          623   48       1  ...        1      0     0\n",
              "\n",
              "[8000 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw9aG4OhkH46"
      },
      "source": [
        "Standardize features by removing the mean and scaling to unit variance\n",
        "\n",
        "The standard score of a sample x is calculated as:\n",
        "\n",
        "z = (x - u) / s\n",
        "\n",
        "where u is the mean of the training samples or zero if with_mean=False, and s is the standard deviation of the training samples or one if with_std=False.\n",
        "\n",
        "Centering and scaling happen independently on each feature by computing the relevant statistics on the samples in the training set. Mean and standard deviation are then stored to be used on later data using transform.\n",
        "\n",
        "Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance).\n",
        "\n",
        "For instance many elements used in the objective function of a learning algorithm (such as the RBF kernel of Support Vector Machines or the L1 and L2 regularizers of linear models) assume that all features are centered around 0 and have variance in the same order. If a feature has a variance that is orders of magnitude larger that others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected.\n",
        "\n",
        "This scaler can also be applied to sparse CSR or CSC matrices by passing with_mean=False to avoid breaking the sparsity structure of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGK952Z1jk1P"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWbwrUXIj9fN",
        "outputId": "fea5a58f-f2e6-4181-87a6-d9b2ee6f87ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_test"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.55204276, -0.36890377,  1.04473698, ...,  1.75486502,\n",
              "        -0.57369368, -1.09168714],\n",
              "       [-1.31490297,  0.10961719, -1.031415  , ..., -0.5698444 ,\n",
              "        -0.57369368, -1.09168714],\n",
              "       [ 0.57162971,  0.30102557,  1.04473698, ..., -0.5698444 ,\n",
              "         1.74309049, -1.09168714],\n",
              "       ...,\n",
              "       [-0.74791227, -0.27319958, -1.37744033, ..., -0.5698444 ,\n",
              "         1.74309049,  0.91601335],\n",
              "       [-0.00566991, -0.46460796, -0.33936434, ...,  1.75486502,\n",
              "        -0.57369368,  0.91601335],\n",
              "       [-0.79945688, -0.84742473,  1.04473698, ...,  1.75486502,\n",
              "        -0.57369368,  0.91601335]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUjoSBc4kAUu",
        "outputId": "30e98f44-e6fc-4e15-a618-8fa1b9882f53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_test"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.55204276, -0.36890377,  1.04473698, ...,  1.75486502,\n",
              "        -0.57369368, -1.09168714],\n",
              "       [-1.31490297,  0.10961719, -1.031415  , ..., -0.5698444 ,\n",
              "        -0.57369368, -1.09168714],\n",
              "       [ 0.57162971,  0.30102557,  1.04473698, ..., -0.5698444 ,\n",
              "         1.74309049, -1.09168714],\n",
              "       ...,\n",
              "       [-0.74791227, -0.27319958, -1.37744033, ..., -0.5698444 ,\n",
              "         1.74309049,  0.91601335],\n",
              "       [-0.00566991, -0.46460796, -0.33936434, ...,  1.75486502,\n",
              "        -0.57369368,  0.91601335],\n",
              "       [-0.79945688, -0.84742473,  1.04473698, ...,  1.75486502,\n",
              "        -0.57369368,  0.91601335]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2dc1ztMargE"
      },
      "source": [
        "Keras is an open-source library that provides a Python interface for artificial neural networks. Keras acts as an interface for the TensorFlow library.\n",
        "\n",
        "Up until version 2.3 Keras supported multiple backends, including TensorFlow, Microsoft Cognitive Toolkit, R, Theano, and PlaidML.[2][3][4] Designed to enable fast experimentation with deep neural networks, it focuses on being user-friendly, modular, and extensible. It was developed as part of the research effort of project ONEIROS (Open-ended Neuro-Electronic Intelligent Robot Operating System),[5] and its primary author and maintainer is François Chollet, a Google engineer. Chollet also is the author of the XCeption deep neural network model.[6\n",
        "\n",
        "**A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--r3da-tba2W"
      },
      "source": [
        "# Dense implements the operation: output = activation(dot(input, kernel) + bias) where activation is the element-wise activation function passed as the activation argument, kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is True).\n",
        "\n",
        "Note: If the input to the layer has a rank greater than 2, then Dense computes the dot product between the inputs and the kernel along the last axis of the inputs and axis 1 of the kernel (using tf.tensordot). For example, if input has dimensions (batch_size, d0, d1), then we create a kernel with shape (d1, units), and the kernel operates along axis 2 of the input, on every sub-tensor of shape (1, 1, d1) (there are batch_size * d0 such sub-tensors). The output in this case will have shape (batch_size, d0, units).\n",
        "\n",
        "Besides, layer attributes cannot be modified after the layer has been called once (except the trainable attribute)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjlX46iabeUu"
      },
      "source": [
        "Parametric ReLU (PReLU) is a type of leaky ReLU that, instead of having a predetermined slope like 0.01, makes it a parameter for the neural network to figure out itself: y = ax when x < 0. Leaky ReLU has two benefits: It fixes the “dying ReLU” problem, as it doesn't have zero-slope parts. It speeds up training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoiIpqL6b0o9"
      },
      "source": [
        "Simply put, dropout refers to ignoring units (i.e. neurons) during the training phase of certain set of neurons which is chosen at random. By “ignoring”, I mean these units are not considered during a particular forward or backward pass.\n",
        "More technically, At each training stage, individual nodes are either dropped out of the net with probability 1-p or kept with probability p, so that a reduced network is left; incoming and outgoing edges to a dropped-out node are also removed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRiDEDsUaErt"
      },
      "source": [
        "#Importing the keras libaries and packages \n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "#from keras.layers import leakyRelu,PReLu,ELU\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efy6dzqsb4fc"
      },
      "source": [
        "#initializing the ANN\n",
        "classifier = Sequential()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzb2Ef8Hb9II",
        "outputId": "d2c1ac37-241a-48fe-8d68-4c30b5200826",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Adding the input layer and first hidden layer\n",
        "classifier.add(Dense(units=6,kernel_initializer=\"he_uniform\",activation=\"relu\",input_dim=11))\n",
        "#adding the second hidden layer \n",
        "classifier.add(Dense(units=6,kernel_initializer =\"he_uniform\",activation='relu'))\n",
        "#adding output layer\n",
        "classifier.add(Dense(units=1,kernel_initializer='glorot_uniform',activation='sigmoid'))\n",
        "#compiling the ANN\n",
        "classifier.compile(optimizer='adamax',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "#fitting the ANN to training set\n",
        "model_history=classifier.fit(x_train,y_train,validation_split=0.33,batch_size=10,epochs=100)\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.5253 - accuracy: 0.7962 - val_loss: 0.5056 - val_accuracy: 0.7955\n",
            "Epoch 2/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.5046 - accuracy: 0.7962 - val_loss: 0.5052 - val_accuracy: 0.7955\n",
            "Epoch 3/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.5039 - accuracy: 0.7962 - val_loss: 0.5043 - val_accuracy: 0.7955\n",
            "Epoch 4/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.5032 - accuracy: 0.7962 - val_loss: 0.5033 - val_accuracy: 0.7955\n",
            "Epoch 5/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.5016 - accuracy: 0.7962 - val_loss: 0.5017 - val_accuracy: 0.7955\n",
            "Epoch 6/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.5000 - accuracy: 0.7962 - val_loss: 0.5001 - val_accuracy: 0.7955\n",
            "Epoch 7/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4978 - accuracy: 0.7962 - val_loss: 0.4979 - val_accuracy: 0.7955\n",
            "Epoch 8/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4953 - accuracy: 0.7962 - val_loss: 0.4944 - val_accuracy: 0.7955\n",
            "Epoch 9/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4919 - accuracy: 0.7962 - val_loss: 0.4912 - val_accuracy: 0.7955\n",
            "Epoch 10/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4887 - accuracy: 0.7962 - val_loss: 0.4874 - val_accuracy: 0.7955\n",
            "Epoch 11/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4849 - accuracy: 0.7962 - val_loss: 0.4847 - val_accuracy: 0.7955\n",
            "Epoch 12/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4812 - accuracy: 0.7962 - val_loss: 0.4805 - val_accuracy: 0.7955\n",
            "Epoch 13/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4779 - accuracy: 0.7962 - val_loss: 0.4780 - val_accuracy: 0.7955\n",
            "Epoch 14/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4748 - accuracy: 0.7962 - val_loss: 0.4754 - val_accuracy: 0.7955\n",
            "Epoch 15/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4732 - accuracy: 0.7962 - val_loss: 0.4752 - val_accuracy: 0.7955\n",
            "Epoch 16/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4716 - accuracy: 0.7962 - val_loss: 0.4743 - val_accuracy: 0.7955\n",
            "Epoch 17/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4711 - accuracy: 0.7962 - val_loss: 0.4756 - val_accuracy: 0.7955\n",
            "Epoch 18/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4703 - accuracy: 0.7962 - val_loss: 0.4740 - val_accuracy: 0.7955\n",
            "Epoch 19/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4696 - accuracy: 0.7962 - val_loss: 0.4731 - val_accuracy: 0.7955\n",
            "Epoch 20/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4691 - accuracy: 0.7962 - val_loss: 0.4732 - val_accuracy: 0.7955\n",
            "Epoch 21/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4689 - accuracy: 0.7962 - val_loss: 0.4745 - val_accuracy: 0.7955\n",
            "Epoch 22/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4684 - accuracy: 0.7962 - val_loss: 0.4745 - val_accuracy: 0.7955\n",
            "Epoch 23/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4686 - accuracy: 0.7962 - val_loss: 0.4734 - val_accuracy: 0.7955\n",
            "Epoch 24/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4685 - accuracy: 0.7962 - val_loss: 0.4748 - val_accuracy: 0.7955\n",
            "Epoch 25/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4684 - accuracy: 0.7962 - val_loss: 0.4743 - val_accuracy: 0.7955\n",
            "Epoch 26/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4674 - accuracy: 0.7962 - val_loss: 0.4743 - val_accuracy: 0.7955\n",
            "Epoch 27/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4674 - accuracy: 0.7962 - val_loss: 0.4747 - val_accuracy: 0.7955\n",
            "Epoch 28/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4674 - accuracy: 0.7962 - val_loss: 0.4740 - val_accuracy: 0.7955\n",
            "Epoch 29/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4666 - accuracy: 0.7962 - val_loss: 0.4739 - val_accuracy: 0.7955\n",
            "Epoch 30/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4669 - accuracy: 0.7962 - val_loss: 0.4761 - val_accuracy: 0.7955\n",
            "Epoch 31/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4664 - accuracy: 0.7962 - val_loss: 0.4742 - val_accuracy: 0.7955\n",
            "Epoch 32/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4669 - accuracy: 0.7962 - val_loss: 0.4739 - val_accuracy: 0.7955\n",
            "Epoch 33/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4662 - accuracy: 0.7962 - val_loss: 0.4746 - val_accuracy: 0.7955\n",
            "Epoch 34/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4657 - accuracy: 0.7962 - val_loss: 0.4739 - val_accuracy: 0.7955\n",
            "Epoch 35/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4657 - accuracy: 0.7962 - val_loss: 0.4731 - val_accuracy: 0.7955\n",
            "Epoch 36/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4657 - accuracy: 0.7962 - val_loss: 0.4741 - val_accuracy: 0.7955\n",
            "Epoch 37/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4656 - accuracy: 0.7962 - val_loss: 0.4749 - val_accuracy: 0.7955\n",
            "Epoch 38/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4657 - accuracy: 0.7962 - val_loss: 0.4737 - val_accuracy: 0.7955\n",
            "Epoch 39/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4651 - accuracy: 0.7962 - val_loss: 0.4737 - val_accuracy: 0.7955\n",
            "Epoch 40/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4653 - accuracy: 0.7962 - val_loss: 0.4736 - val_accuracy: 0.7955\n",
            "Epoch 41/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4652 - accuracy: 0.7962 - val_loss: 0.4746 - val_accuracy: 0.7955\n",
            "Epoch 42/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4649 - accuracy: 0.7962 - val_loss: 0.4737 - val_accuracy: 0.7955\n",
            "Epoch 43/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4650 - accuracy: 0.7962 - val_loss: 0.4763 - val_accuracy: 0.7955\n",
            "Epoch 44/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4645 - accuracy: 0.7962 - val_loss: 0.4741 - val_accuracy: 0.7955\n",
            "Epoch 45/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4650 - accuracy: 0.7962 - val_loss: 0.4736 - val_accuracy: 0.7955\n",
            "Epoch 46/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4641 - accuracy: 0.7962 - val_loss: 0.4742 - val_accuracy: 0.7955\n",
            "Epoch 47/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4640 - accuracy: 0.7962 - val_loss: 0.4763 - val_accuracy: 0.7955\n",
            "Epoch 48/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4650 - accuracy: 0.7962 - val_loss: 0.4738 - val_accuracy: 0.7955\n",
            "Epoch 49/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4643 - accuracy: 0.7962 - val_loss: 0.4741 - val_accuracy: 0.7955\n",
            "Epoch 50/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4646 - accuracy: 0.7962 - val_loss: 0.4740 - val_accuracy: 0.7955\n",
            "Epoch 51/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4641 - accuracy: 0.7962 - val_loss: 0.4734 - val_accuracy: 0.7955\n",
            "Epoch 52/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4647 - accuracy: 0.7962 - val_loss: 0.4733 - val_accuracy: 0.7955\n",
            "Epoch 53/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4640 - accuracy: 0.7962 - val_loss: 0.4745 - val_accuracy: 0.7955\n",
            "Epoch 54/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4639 - accuracy: 0.7962 - val_loss: 0.4732 - val_accuracy: 0.7955\n",
            "Epoch 55/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4640 - accuracy: 0.7962 - val_loss: 0.4740 - val_accuracy: 0.7955\n",
            "Epoch 56/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4645 - accuracy: 0.7962 - val_loss: 0.4748 - val_accuracy: 0.7955\n",
            "Epoch 57/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4639 - accuracy: 0.7962 - val_loss: 0.4741 - val_accuracy: 0.7955\n",
            "Epoch 58/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4641 - accuracy: 0.7962 - val_loss: 0.4744 - val_accuracy: 0.7955\n",
            "Epoch 59/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4645 - accuracy: 0.7962 - val_loss: 0.4752 - val_accuracy: 0.7955\n",
            "Epoch 60/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4637 - accuracy: 0.7962 - val_loss: 0.4738 - val_accuracy: 0.7955\n",
            "Epoch 61/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4640 - accuracy: 0.7962 - val_loss: 0.4758 - val_accuracy: 0.7955\n",
            "Epoch 62/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4642 - accuracy: 0.7962 - val_loss: 0.4767 - val_accuracy: 0.7955\n",
            "Epoch 63/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4634 - accuracy: 0.7962 - val_loss: 0.4750 - val_accuracy: 0.7955\n",
            "Epoch 64/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4639 - accuracy: 0.7962 - val_loss: 0.4743 - val_accuracy: 0.7955\n",
            "Epoch 65/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4639 - accuracy: 0.7962 - val_loss: 0.4744 - val_accuracy: 0.7955\n",
            "Epoch 66/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4637 - accuracy: 0.7962 - val_loss: 0.4737 - val_accuracy: 0.7955\n",
            "Epoch 67/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4635 - accuracy: 0.7962 - val_loss: 0.4742 - val_accuracy: 0.7955\n",
            "Epoch 68/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4638 - accuracy: 0.7962 - val_loss: 0.4742 - val_accuracy: 0.7955\n",
            "Epoch 69/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4641 - accuracy: 0.7962 - val_loss: 0.4745 - val_accuracy: 0.7955\n",
            "Epoch 70/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4632 - accuracy: 0.7962 - val_loss: 0.4741 - val_accuracy: 0.7955\n",
            "Epoch 71/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4639 - accuracy: 0.7962 - val_loss: 0.4742 - val_accuracy: 0.7955\n",
            "Epoch 72/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4634 - accuracy: 0.7962 - val_loss: 0.4749 - val_accuracy: 0.7955\n",
            "Epoch 73/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4645 - accuracy: 0.7962 - val_loss: 0.4744 - val_accuracy: 0.7955\n",
            "Epoch 74/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4634 - accuracy: 0.7962 - val_loss: 0.4735 - val_accuracy: 0.7955\n",
            "Epoch 75/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4633 - accuracy: 0.7962 - val_loss: 0.4763 - val_accuracy: 0.7955\n",
            "Epoch 76/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4637 - accuracy: 0.7962 - val_loss: 0.4754 - val_accuracy: 0.7955\n",
            "Epoch 77/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4634 - accuracy: 0.7962 - val_loss: 0.4744 - val_accuracy: 0.7955\n",
            "Epoch 78/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4632 - accuracy: 0.7962 - val_loss: 0.4735 - val_accuracy: 0.7955\n",
            "Epoch 79/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4640 - accuracy: 0.7962 - val_loss: 0.4743 - val_accuracy: 0.7955\n",
            "Epoch 80/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4632 - accuracy: 0.7962 - val_loss: 0.4741 - val_accuracy: 0.7955\n",
            "Epoch 81/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4631 - accuracy: 0.7962 - val_loss: 0.4750 - val_accuracy: 0.7955\n",
            "Epoch 82/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4627 - accuracy: 0.7962 - val_loss: 0.4750 - val_accuracy: 0.7955\n",
            "Epoch 83/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4635 - accuracy: 0.7962 - val_loss: 0.4757 - val_accuracy: 0.7955\n",
            "Epoch 84/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4630 - accuracy: 0.7962 - val_loss: 0.4746 - val_accuracy: 0.7955\n",
            "Epoch 85/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4631 - accuracy: 0.7962 - val_loss: 0.4737 - val_accuracy: 0.7955\n",
            "Epoch 86/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4633 - accuracy: 0.7962 - val_loss: 0.4749 - val_accuracy: 0.7955\n",
            "Epoch 87/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4631 - accuracy: 0.7962 - val_loss: 0.4742 - val_accuracy: 0.7955\n",
            "Epoch 88/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4636 - accuracy: 0.7962 - val_loss: 0.4752 - val_accuracy: 0.7955\n",
            "Epoch 89/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4631 - accuracy: 0.7962 - val_loss: 0.4748 - val_accuracy: 0.7955\n",
            "Epoch 90/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4635 - accuracy: 0.7962 - val_loss: 0.4755 - val_accuracy: 0.7955\n",
            "Epoch 91/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4624 - accuracy: 0.7962 - val_loss: 0.4749 - val_accuracy: 0.7955\n",
            "Epoch 92/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4635 - accuracy: 0.7962 - val_loss: 0.4746 - val_accuracy: 0.7955\n",
            "Epoch 93/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.4635 - accuracy: 0.7962 - val_loss: 0.4740 - val_accuracy: 0.7955\n",
            "Epoch 94/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4623 - accuracy: 0.7962 - val_loss: 0.4762 - val_accuracy: 0.7955\n",
            "Epoch 95/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4637 - accuracy: 0.7962 - val_loss: 0.4745 - val_accuracy: 0.7955\n",
            "Epoch 96/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4629 - accuracy: 0.7962 - val_loss: 0.4752 - val_accuracy: 0.7955\n",
            "Epoch 97/100\n",
            "536/536 [==============================] - 1s 3ms/step - loss: 0.4625 - accuracy: 0.7962 - val_loss: 0.4778 - val_accuracy: 0.7955\n",
            "Epoch 98/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4631 - accuracy: 0.7962 - val_loss: 0.4753 - val_accuracy: 0.7955\n",
            "Epoch 99/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4628 - accuracy: 0.7962 - val_loss: 0.4756 - val_accuracy: 0.7955\n",
            "Epoch 100/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4623 - accuracy: 0.7962 - val_loss: 0.4752 - val_accuracy: 0.7955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU-IjwQxmGgK",
        "outputId": "2c875cd8-c4c6-483b-b777-22b5afa5b78c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#list all data in history\n",
        "print(model_history.history.keys())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_dPXOKGmaET",
        "outputId": "fd6f6cd8-8969-4bfd-cbfe-58ff8f6dd289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "#summarize history for accuracy\n",
        "plt.plot(model_history.history['accuracy'])\n",
        "plt.plot(model_history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'],loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE4QXpN2nYaG"
      },
      "source": [
        "#part3 -making the prediction and evaluating the model\n",
        "#predicting the confusion matrix \n",
        "y_pred = classifier.predict(x_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test,y_pred)\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TPblGSnn0lx"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "score = accuracy_score(y_pred,y_test)\n"
      ],
      "execution_count": 49,
      "outputs": []
    }
  ]
}